{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "Change parallel arrays for checking accuracy to data frame instead <br>\n",
    "\n",
    "BEFORE PUTTING ON GITHUB!!! <br>\n",
    "Very small step in prediction mesh <br>\n",
    "Range of k-values to try <br>\n",
    "File name (not the partial data file) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import neighbors\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data\n",
    "Indicate the name of the csv file with a column to each parameter, a row to each trial, and both row and column headers. The classification indicator must be the last column and contain either the integer 0 or 1 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDataFileName = 'PartialParameterData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into data frame, ignoring the 1st column of trial indices\n",
    "with open(inputDataFileName) as f:\n",
    "    ncols = len(f.readline().split(','))\n",
    "\n",
    "parameterDF = pd.read_csv(inputDataFileName, delimiter=',', index_col=0, header=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the indexing column and reset the indices\n",
    "parameterDF = parameterDF.reset_index()\n",
    "del parameterDF['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "params = parameterDF.columns.tolist() # List of labels for indexing\n",
    "normDF = DataFrame()\n",
    "\n",
    "for param in params[:-1]: # Normalize each parameter column (not classification column)\n",
    "    normalizedData = ( parameterDF[param] - parameterDF[param].mean() ) / parameterDF[param].std()\n",
    "    normDF = pd.concat( [normDF, Series(normalizedData) ], axis=1 )\n",
    "    normDF.rename( columns={ 0:param } )\n",
    "\n",
    "# Add the classification column back in\n",
    "normDF = pd.concat( [normDF, parameterDF[ params[-1] ] ], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by classification\n",
    "groups = normDF.groupby( normDF.columns[-1] )\n",
    "successGroup = groups.get_group(1)\n",
    "failureGroup = groups.get_group(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find optimal k and weight method for each pair of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numParams = len(params)-1 # For looping through parameters\n",
    "\n",
    "# Set the range of values of k around the typical standard for k=sqrt(n)\n",
    "# And only look at the odd values for k\n",
    "kMid = (int)( sqrt(parameterDF.shape[0]) ) # k nearest neighbors\n",
    "\n",
    "if kMid%2 is 0: # Want odd k\n",
    "    kMid = kMid + 1\n",
    "    \n",
    "kBeg = kMid - 4\n",
    "kEnd = kMid + 2\n",
    "ks = np.arange(kBeg, kEnd, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestClassifiersByWeight = []\n",
    "overallBestClassifiers = []\n",
    "overallBestKs = []\n",
    "overallBestAccValues = []\n",
    "overallBestWeights = []\n",
    "\n",
    "accScoresByWeight = []\n",
    "allAccScores = [] \n",
    "\n",
    "xMins = []\n",
    "xMaxs = []\n",
    "yMins = []\n",
    "yMaxs = []\n",
    "\n",
    "comparisons = []\n",
    "\n",
    "maxAccValues = []\n",
    "bestKs = []\n",
    "bestClassifiers = []\n",
    "accScoresByParams = []\n",
    "\n",
    "# Create list of comparison labels\n",
    "for xNum in range(numParams):\n",
    "    for yNum in range(numParams):\n",
    "        if xNum < yNum:\n",
    "            comparisons.append( params[xNum]+' vs '+params[yNum] )\n",
    "            \n",
    "\n",
    "for rowNum in range(numParams):    \n",
    "\n",
    "    for colNum in range(numParams): \n",
    "\n",
    "        # Now inside the loop for each set of params\n",
    "\n",
    "        if rowNum < colNum: # Exclude repeated plots \n",
    "\n",
    "            # Now inside the loop for each set of params we use (without the ones we don't use)\n",
    "            print()\n",
    "            print( '     '+str(params[colNum]) + ' vs ' + str(params[rowNum]) + ':')                \n",
    "\n",
    "            XTrains = []\n",
    "            XTests = []\n",
    "            yTrains = []\n",
    "            yTests = []\n",
    "\n",
    "            accuracyScores = [] \n",
    "            classifiers = []\n",
    "\n",
    "            # Get data\n",
    "            x1 = normDF[ params[colNum] ] # x-axis\n",
    "            x2 = normDF[ params[rowNum] ] # y-axis\n",
    "            X = np.column_stack( (x1, x2) )\n",
    "\n",
    "            # Get overall min and max values for plotting and prediction testing\n",
    "            xMin, xMax = x1.min(), x1.max() \n",
    "            yMin, yMax = x2.min(), x2.max()            \n",
    "            xMins.append(xMin), xMaxs.append(xMax), yMins.append(yMin), yMaxs.append(yMax)           \n",
    "\n",
    "            # Split data into training and testing samples\n",
    "            XTrain, XTest, yTrain, yTest = train_test_split(X, normDF[ params[-1] ])            \n",
    "            XTrains.append(XTrain), XTests.append(XTest), yTrains.append(yTrain), yTests.append(yTest)            \n",
    "            # USING SAME DATA FOR TRAINING VS TESTING FOR EACH K THAT WE TRY\n",
    "\n",
    "            # loop for each k\n",
    "            for k in ks:\n",
    "\n",
    "                # Now inside the loop for each k for the set of params\n",
    "\n",
    "                # Fit the classifier\n",
    "                classifier = neighbors.KNeighborsClassifier( k ).fit(XTrain, yTrain)\n",
    "                classifiers.append(classifier)                \n",
    "\n",
    "                # Predict test data and find accuracy for this k\n",
    "                predicted = classifier.predict( XTest )\n",
    "                acc = accuracy_score( yTest, predicted )\n",
    "                accuracyScores.append( acc )  \n",
    "                print('          k = '+str(k)+'  accuracy = '+str(acc))\n",
    "\n",
    "            # Now back to the loop for each set of params that we use\n",
    "\n",
    "            # Find the best accuracy for this set of params, get the cooresponding k and classifier\n",
    "            maxAccIndex, maxAccValue = max(enumerate(accuracyScores), key=operator.itemgetter(1))\n",
    "            bestK = ks[maxAccIndex]\n",
    "            maxAccValues.append( maxAccValue ) # actual accuracy\n",
    "            bestKs.append( bestK ) # just to know \n",
    "            bestClassifiers.append( classifiers[maxAccIndex] ) # for plotting  \n",
    "            accScoresByParams.append(accuracyScores)\n",
    "\n",
    "            print()\n",
    "            print( '          Max accuracy at k=' + str(bestK) + ' at ' + str(maxAccValue) )\n",
    "\n",
    "        # Back to the loop for each set of params (with repeats)\n",
    "    overallBestClassifiers.append( bestClassifiers )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training data & prediction boundaries with optimized accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHANGE STEP SIZE FOR PREDICTION MESH!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.005  # Step size in the prediction mesh\n",
    "colMap = ListedColormap( ['#F08080', '#98FB98'] ) # Prediction mesh colors\n",
    "meshXs = []\n",
    "meshYs = []\n",
    "meshPredictions = [] \n",
    "\n",
    "# Predict a meshgrid of data points\n",
    "for num in range( len(bestClassifiers) ):\n",
    "    meshX, meshY = np.meshgrid(np.arange(xMins[num]-1, xMaxs[num]+1, h),\n",
    "                               np.arange(yMins[num]-1, yMaxs[num]+1, h))\n",
    "    meshXs.append(meshX), meshYs.append(meshY)\n",
    "    meshPredicted = bestClassifiers[num].predict(np.c_[meshX.ravel(), meshY.ravel()])\n",
    "    meshPredicted = meshPredicted.reshape(meshX.shape)\n",
    "    meshPredictions.append(meshPredicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the figure for plotting\n",
    "plt.rcParams.update({'figure.autolayout': False})\n",
    "plt.figure( figsize=(15,15) )\n",
    "G = gridspec.GridSpec(numParams, numParams)\n",
    "plt.subplots_adjust( hspace=0.1, wspace=0.1 ) \n",
    "plt.rc('font', size=20)\n",
    "plt.suptitle('Optimized KNN Classifiers', x=0.5, y=0.9)\n",
    "axarr = []\n",
    "indices = [] # For indexing row and column labels\n",
    "\n",
    "for xNum in range(numParams):\n",
    "    for yNum in range(numParams):\n",
    "        if xNum < yNum:\n",
    "            indices.append( (params[xNum],params[yNum]) ) \n",
    "            ax = plt.subplot( G[yNum-1, xNum] )\n",
    "            axarr.append(ax)\n",
    "            if xNum is 0:\n",
    "                plt.ylabel( params[yNum] )\n",
    "            if xNum is not 0:\n",
    "                plt.yticks( visible=False )\n",
    "            if yNum is numParams-1:\n",
    "                plt.xlabel( params[xNum] )\n",
    "                plt.xticks( rotation=45 )\n",
    "            if yNum is not numParams-1:\n",
    "                plt.xticks( visible=False ) \n",
    "                         \n",
    "# Plot \n",
    "for num in range(len(indices)):                \n",
    "    # Plot decision boundary\n",
    "    axarr[num].pcolormesh(meshXs[num], meshYs[num], meshPredictions[num], cmap=colMap)\n",
    "    \n",
    "    # Plot the training data \n",
    "    xSuccesses = successGroup[ indices[num][1] ].head(200)\n",
    "    ySuccesses = successGroup[ indices[num][0] ].head(200)\n",
    "    axarr[num].scatter( xSuccesses, ySuccesses, marker='o', color='#006400', alpha=0.7, label='success' )\n",
    "    \n",
    "    xFailures = failureGroup[ indices[num][1] ].head(200)\n",
    "    yFailures = failureGroup[ indices[num][0] ].head(200)\n",
    "    axarr[num].scatter( xFailures, yFailures, marker='s', color='#FF0000', alpha=0.7, label='failure')\n",
    "            \n",
    "    axarr[num].set_xlim( -3,3 )\n",
    "    axarr[num].set_ylim( -3,3 ) \n",
    "            \n",
    "#plt.legend(bbox_to_anchor=(1,1), loc=0, borderaxespad=-4)\n",
    "#plt.legend(bbox_to_anchor=(1,1), loc=1, borderaxespad=-4)\n",
    "plt.legend(bbox_to_anchor=(1,1), loc=2, borderaxespad=-11)\n",
    "plt.savefig('KNNPlotOptimized.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
